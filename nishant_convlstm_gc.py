# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mwo3rmtjws9OecCj8xNWyxpeu2nfVgiT
"""

from keras.models import Sequential
from keras.layers import Dropout
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional_recurrent import ConvLSTM2D
import numpy as np
#import matplotlib.pyplot as plt
from keras.optimizers import Adam, SGD, RMSprop, Adagrad
#from keras.wrappers.scikit_learn import KerasClassifier
#from sklearn.model_selection import GridSearchCV

#Uploading data from computer
"""
from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
"""

fn = 'sliced_32x32.npy'

data = np.load(fn)

#work_data = data[:101]

#, metrics = ['accuracy'])

#X = np.random.randn(10,100,32,32,1)
# 10 observations, 100 timesteps, 32 width, 32 height, channel 1
#y = np.random.randn(10 observatons,32 width,32 height,1 channel)


def prep_data(data, height, width, lookback, max_obs, scale = False):
    '''
    '''
    x = data[:max_obs, :height, :width]
    y = data[1:max_obs+1, :height, :width]
    x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])
    y = y.reshape(y.shape[0], 1, y.shape[1], y.shape[2])
    
    w = x.shape[0]-lookback+1
    
    t1 = np.zeros((w, lookback, 1, height, width))
    t2 = np.zeros((w, lookback, 1, height, width))
    
    for i in range(w):
        t1[i,:,:,:,:]=x[i:i+lookback,:,:,:]
        t2[i,:,:,:,:]=y[i:i+lookback,:,:,:]
    
    return t1 , t2[:,-1]


def create_model(look_back = 20, lr= 0.001 , decay = 0.0005, f1 = 16, f2 = 8):
    '''
    '''
    model = Sequential([
            ConvLSTM2D(filters = f1,
                       kernel_size = (3, 3), 
                       input_shape = (look_back, 1, 32, 32),      
                       padding = 'same',
                       data_format = 'channels_first',
                       return_sequences = True),
           
           # Dropout(0.5),
        
            ConvLSTM2D(filters = f2,
                       kernel_size = (3, 3),                       
                       padding = 'same',
                       data_format = 'channels_first',
                       return_sequences = False),
        
            Conv2D(filters = 1,
                   kernel_size = (1, 1),
                   activation = 'relu',
                   padding = 'same',
                   data_format = 'channels_first')])
            
    optim = Adam(lr = lr, 
                decay = decay
               )
    
    model.compile(loss = 'mse', optimizer = optim, metrics=['mae'])
    
    return model


pr = dict()

#x,y = prep_data(data, 32, 32 , 20, 100)
#act = ['relu']

look_back = 20
lr = 0.0005
decay = 0.0005
f1 = 32
f2 = 16
#batch_size = [10,20,30,40]
epochs = 100

x,y = prep_data(data, 32,32,look_back,100)
model = create_model(look_back,lr,decay,f1,f2)
h = model.fit(x,y, epochs = epochs, validation_split=0.3)


"""

from tqdm import tqdm
#for a in tqdm(act):
for l in tqdm(lr):
    for d in dec:
        for fi in f1:
            for fii in f2:
                for lb in look_back:
                    for ep in epochs:
                        x,y = prep_data(data, 32,32,lb,100)
                        model = create_model(lb,l,d,fi,fii)
                        h = model.fit(x,y, epochs = ep)
                        #pr[str(l)+'_'+str(d)+'_'+str(fi)+'_'+str(fii)+'_'+str(lb)]=h.history['loss']
                        with open(str(l)+'_'+str(d)+'_'+str(fi)+'_'+str(fii)+'_'+str(lb)+'_'+str(ep)+'.txt','w') as f:
                            f.write('Learning Rate : '+str(l)+'\n')
                            f.write('Decay : '+str(d)+'\n')
                            f.write('ConvLSTM2D L1 Filter : '+str(fi)+'\n')
                            f.write('ConvLSTM2D L2 Filter : '+str(fii)+'\n')
                            f.write('Seq size : '+str(lb)+'\n')
                            f.write('Epochs : '+str(ep)+'\n \n')
                            f.write('Loss: \n \n')
                            for i in h.history['loss']:
                                f.write(str(i)+'\n')
                                
                            
"""


#with open('best.txt','w') as f:
#    f.write('Best Params: \n')
#    f.write('Learningrate_decay_filter1lstm_filter2lstm_seqsize \n')
#    f.write(str(list(pr.keys())[0])+' \n \n')
#    f.write('Loss : \n')
#    for i in pr[list(pr.keys())[0]]:
#        f.write(str(i)+'\n')
    
#model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=1)
#grid = GridSearchCV(estimator=model, param_grid=param_grid)
#grid_result = grid.fit(x, y)
    
#print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
#means = grid_result.cv_results_['mean_test_score']
#stds = grid_result.cv_results_['std_test_score']
#params = grid_result.cv_results_['params']
#for mean, stdev, param in zip(means, stds, params):
#      print("%f (%f) with: %r" % (mean, stdev, param))
#pr[20] = [means, stds, params]
    
#import matplotlib.pyplot as plt
#with open('best.txt') as f:
#    dat = f.readlines()

#x =[float(i) for i in dat[5:]]
#plt.plot(x)

import matplotlib.pyplot as plt

plt.plot(np.sqrt(h.history['loss']))
plt.plot(np.sqrt(h.history['val_loss']),'r')
plt.show()

with open('results-loss'+'.txt','w') as f:
  f.write('Learning Rate : '+str(lr)+'\n')
  f.write('Decay : '+str(decay)+'\n')
  f.write('ConvLSTM2D L1 Filter : '+str(f1)+'\n')
  f.write('ConvLSTM2D L2 Filter : '+str(f2)+'\n')
  f.write('Seq size : '+str(look_back)+'\n')
  f.write('Epochs : '+str(epochs)+'\n \n')
  f.write('Loss: \n \n')
  for i in h.history['loss']:
    f.write(str(i)+'\n')


files.download('results-loss.txt')